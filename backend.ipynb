{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e23beab",
   "metadata": {},
   "source": [
    "This file contains all the backend work related to scraping websites, building database (simulated with creation of csv files) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5d981",
   "metadata": {},
   "source": [
    "## *All the data being scraped is done legally.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe99b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc0fe4",
   "metadata": {},
   "source": [
    "This Cell is used to simulate the workflow of collecting company data from Linkedin from a prebuilt data with company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13) Deloitte_ About _ LinkedIn.html\n",
      "(13) Sony Research India_ About _ LinkedIn.html\n",
      "(14) Accenture_ About _ LinkedIn.html\n",
      "(14) Flipkart_ About _ LinkedIn.html\n",
      "(14) JPMorganChase_ About _ LinkedIn.html\n",
      "(14) NVIDIA_ About _ LinkedIn.html\n",
      "(14) Tata Consultancy Services_ About _ LinkedIn.html\n",
      "['data/(13) Deloitte_ About _ LinkedIn.html', 'data/(13) Sony Research India_ About _ LinkedIn.html', 'data/(14) Accenture_ About _ LinkedIn.html', 'data/(14) Flipkart_ About _ LinkedIn.html', 'data/(14) JPMorganChase_ About _ LinkedIn.html', 'data/(14) NVIDIA_ About _ LinkedIn.html', 'data/(14) Tata Consultancy Services_ About _ LinkedIn.html']\n"
     ]
    }
   ],
   "source": [
    "#This Cell is used to simulate the workflow of collecting company data from Linkedin from a prebuilt data with company names. \n",
    "data_folder = \"data\"\n",
    "\n",
    "websites = []\n",
    "links = []  #Links could be generated from https://linkedin.com/company/about/\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith('.html'):\n",
    "        websites.append(file[:-5])\n",
    "        links.append(data_folder + '/' + file)\n",
    "        print(file)\n",
    "\n",
    "# print(links)\n",
    "\n",
    "# Create a DataFrame and save it to a CSV file. This contains the website names and their corresponding paths stored locally.\n",
    "df = pd.DataFrame({\"websites\": websites, \"paths\": links})\n",
    "df.to_csv(\"websites.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720b1b2",
   "metadata": {},
   "source": [
    "Below cell performs simulated web scraping and data enrichment for all companies.  \n",
    "It extracts key information such as company name, website, industry, specialties, headquarters, quick links, contact details, and overview from local HTML files or cached data.  \n",
    "The enriched dataset is then saved to a CSV file for further analysis or use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "    \n",
    "# This function converts a file path to a file URL.\n",
    "def get_url_from_file(path):\n",
    "    html_path = os.path.abspath(path)\n",
    "    file_url = f\"file:///{html_path.replace(' ', '%20')}\"\n",
    "\n",
    "    return file_url\n",
    "\n",
    "# This function retrieves quick links from the main URL of a company.\n",
    "def get_quick_links(main_url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(main_url)\n",
    "    time.sleep(2)  # Let the page load\n",
    "\n",
    "    links = {\n",
    "        \"about\": [\"about\", \"company\", \"who-we-are\"],\n",
    "        \"contact\": [\"contact\", \"get-in-touch\", \"reach-us\"],\n",
    "        \"services\": [\"service\", \"what-we-do\", \"solutions\"],\n",
    "        \"blog\": [\"blog\", \"news\", \"insights\", \"press\"],\n",
    "        \"investors\": [\"investor\", \"investors\", \"investor-relations\"]\n",
    "    }\n",
    "\n",
    "    section_links = {key: [] for key in links}\n",
    "\n",
    "    for a in driver.find_elements(By.TAG_NAME, \"a\"):\n",
    "        href = a.get_attribute(\"href\")\n",
    "        text = a.text.lower()\n",
    "        if not href:\n",
    "            continue\n",
    "        for section, keywords in links.items():\n",
    "            for kw in keywords:\n",
    "                if (kw in href.lower()) or (kw in text):\n",
    "                    section_links[section].append(href)\n",
    "                    break  # Avoid duplicate for same link in multiple keywords\n",
    "\n",
    "    shortest_links = {}\n",
    "    for section, hrefs in section_links.items():\n",
    "        if hrefs:\n",
    "            shortest_links[section] = min(hrefs, key=len)\n",
    "        else:\n",
    "            shortest_links[section] = None\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    quick_links = {\"Quick_links\": shortest_links}\n",
    "    return quick_links\n",
    "\n",
    "# This function extracts contact information from a given URL.\n",
    "def contact_info(file_url):\n",
    "    if file_url == None:\n",
    "        contact_info = {\"Contact_info\": \n",
    "                        {\n",
    "                \"Email\": \"not available\",\n",
    "                \"Phone\": \"not available\",\n",
    "                \"Location\": \"not available\"\n",
    "            }\n",
    "        }\n",
    "        return contact_info\n",
    "    else:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        driver.get(file_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "\n",
    "        emails = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", html)\n",
    "        email = emails[0] if emails else \"not available\"\n",
    "\n",
    "        # Extract phone numbers (basic pattern)\n",
    "        phones = re.findall(r\"\\+?\\d[\\d\\s().-]{7,}\\d\", html)\n",
    "        phone = phones[0] if phones else \"not available\"\n",
    "\n",
    "        # Extract locations from <address> tags\n",
    "        locations = []\n",
    "        try:\n",
    "            address_elements = driver.find_elements(By.TAG_NAME, \"address\")\n",
    "            for addr in address_elements:\n",
    "                locations.append(addr.text.strip())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        location = locations[0] if locations else \"not available\"\n",
    "\n",
    "        contact_info = {\"Contact_info\": \n",
    "                        {\n",
    "                \"Email\": email,\n",
    "                \"Phone\": phone,\n",
    "                \"Location\": location\n",
    "            }\n",
    "        }\n",
    "        driver.quit()\n",
    "\n",
    "    return contact_info\n",
    "\n",
    "\n",
    "# This function fetches company information from a given URL.\n",
    "def fetch_info_from_url(file_url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    driver.get(file_url)\n",
    "\n",
    "    time.sleep(2)  # Let the page load\n",
    "\n",
    "    try:\n",
    "        # Try the most common LinkedIn company name selector\n",
    "        company_name = driver.find_element(\n",
    "            By.CSS_SELECTOR, \"h1.org-top-card-summary__title\"\n",
    "        ).text.strip()\n",
    "    except:\n",
    "        # Fallback: try a more generic h1 if the above fails\n",
    "        try:\n",
    "            company_name = driver.find_element(By.TAG_NAME, \"h1\").text.strip()\n",
    "        except Exception as e:\n",
    "            company_name = f\"Company name not found: {e}\"\n",
    "\n",
    "    try:\n",
    "        overview = driver.find_element(\n",
    "            By.CSS_SELECTOR,\n",
    "            \"section.org-about-module__margin-bottom p.break-words.white-space-pre-wrap.t-black--light.text-body-medium\"\n",
    "        ).text\n",
    "    except:\n",
    "        overview = \"Overview not found\"\n",
    "\n",
    "    params = {\n",
    "        \"Website\": \"Not Found\",\n",
    "        \"Industry\": \"Not Found\",\n",
    "        \"Specialties\": \"Not Found\",\n",
    "        \"Headquarters\": \"Not Found\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        dl = driver.find_element(By.CSS_SELECTOR, \"dl.overflow-hidden\")\n",
    "        dt_elements = dl.find_elements(By.CSS_SELECTOR, \"dt.mb1\")\n",
    "        dd_elements = dl.find_elements(By.CSS_SELECTOR, \"dd.mb4.t-black--light.text-body-medium\")\n",
    "        \n",
    "        for dt, dd in zip(dt_elements, dd_elements):\n",
    "            label = dt.text.strip()\n",
    "            value = dd.text.strip()\n",
    "            # Only update if label is in our params\n",
    "            for key in params:\n",
    "                if label == key:\n",
    "                    params[key] = value\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting parameters:\", e)\n",
    "\n",
    "    company_size = \"Company size not found\"\n",
    "    try:\n",
    "        dl = driver.find_element(By.CSS_SELECTOR, \"dl.overflow-hidden\")\n",
    "        dt_elements = dl.find_elements(By.CSS_SELECTOR, \"dt.mb1\")\n",
    "        dd_elements = dl.find_elements(By.CSS_SELECTOR, \"dd\")\n",
    "\n",
    "        # Loop through all dt/dd pairs\n",
    "        for dt, dd in zip(dt_elements, dd_elements):\n",
    "            label = dt.text.strip()\n",
    "            value = dd.text.strip()\n",
    "            if \"Company size\" in label:\n",
    "                company_size = value\n",
    "                break\n",
    "    except Exception as e:\n",
    "        company_size = f\"Company size not found: {e}\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    quick_links = get_quick_links(params[\"Website\"])\n",
    "    contact_link = None\n",
    "    if quick_links[\"Quick_links\"][\"contact\"] is not None:\n",
    "        contact_link = quick_links[\"Quick_links\"][\"contact\"]\n",
    "\n",
    "    company_info = {\n",
    "        \"Company Name\": company_name,\n",
    "        \"Website\": params[\"Website\"],\n",
    "        \"Industry\": params[\"Industry\"],\n",
    "        \"Company Size\": company_size,\n",
    "        \"Specialties\": params[\"Specialties\"],\n",
    "        \"Headquarters\": params[\"Headquarters\"],\n",
    "        \"Quick Links\": get_quick_links(params[\"Website\"]),\n",
    "        \"Contact Info\": contact_info(contact_link),\n",
    "        \"Description\": overview   # A Summary of the company could be made using NLP here.\n",
    "    }\n",
    "\n",
    "    return company_info\n",
    "\n",
    "\n",
    "records = []\n",
    "for i in range(len(df)):\n",
    "    path = df['paths'][i]\n",
    "    file_url = get_url_from_file(path)\n",
    "\n",
    "    info = fetch_info_from_url(file_url)\n",
    "\n",
    "    records.append(info)\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save the DataFrame to a CSV file. Applicable to new and existing files\n",
    "if os.path.exists(\"data.csv\"):\n",
    "    df.to_csv(\"data.csv\", mode='a', header=False, index=False)\n",
    "else:\n",
    "    df.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
